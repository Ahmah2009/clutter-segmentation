% \chapter{Theory}
% \label{chapter:theory}

\section{Object Recognition}

We can model unknown variables in a random distribution. When given a query
image, we obtain a set of local features. This is the sample we observe. Every
feature in this set has been generated by a textured object or by textured
background. A feature consists of a 2d location and a feature descriptor. We
can regard a template object as a distribution. Then a scene corresponds to a
mixed distribution. Our task is then to decide which query feature was
generated by what object and derive a pose. Since we do not know which objects
are in the scene, we do not know which distributions have generated the sample.
Detecting objects in a scene is nothing else than guessing which distributions
have generated the feature sets. When we also want to locate the pose, we have
to estimate further parameters. This is made difficult, since there might be
similar feature descriptors on the same object and also similar feature
descriptors from multiple objects. There does not exist an inverse relationship
between feature descriptors and the object that generated it. We can only
decide on likelihood criteria, for example we assign each feature to the
template object which has the most similar feature descriptor from all template
objects (nearest neighbor). If a query feature descriptor has close neighbors
to training descriptors from more than one template object, then this query
feature is difficult to discriminate and we might ignore this feature.

\section{Classifier Evaluation}

